{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa48e7d10bb49ad9eb2d2c6e800d415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/545 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b765f13916ed47c3b48c9ad072dc53bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1902ff5825041ec97c492ecfa34b9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c67c886a0e4ddbbf4268cfad7b4901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a326a59558c249a9b268f802381aff15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50203871114c41fb80b169a2d1efa3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/712M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7445e9273983466c9f2b53e23c864e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/323 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01592a5b18424ac5b0c77920773cc458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ad18bc69ff4c329782e0a3b45e1f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a690e245954a61877d959e1ffa5b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800194ed6f9049599a2f31d68e71668a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a775253101b24986a21dbe00859f29c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ecd09240b84fb69ba875c827047077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ee5f2bc57b4882aaf94dfa84fefbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd2237f678e4737a973aeece58a1ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/551M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel, GPT2LMHeadModel\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import scipy\n",
    "import json\n",
    "\n",
    "def perform_nli(premise, hypothesis):\n",
    "    with torch.inference_mode():\n",
    "        out = nli_model(**nli_tokenizer(premise, hypothesis, return_tensors='pt'))\n",
    "        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n",
    "    return {v: proba[k] for k, v in nli_model.config.id2label.items()}\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def get_embedding(sentences):\n",
    "    encoded_input = sbert_tokenizer(sentences, padding=True, truncation=False, return_tensors='pt')\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        model_output = sbert_model(**encoded_input)\n",
    "\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    return sentence_embeddings\n",
    "\n",
    "def estimate_perplexity(text):\n",
    "    inputs = gpt_tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.inference_mode():\n",
    "        loss = gpt_model(**inputs, labels=inputs[\"input_ids\"]).loss\n",
    "    return loss.item()\n",
    "\n",
    "def get_mean_dist(text, embeds, k=10):\n",
    "    embed = get_embedding(text).numpy()\n",
    "    dists = scipy.spatial.distance.cdist(embed, compare_embeds, metric=\"cosine\")[0]\n",
    "    return np.partition(dists, k)[:k].mean()\n",
    "\n",
    "def score(premise: str, hypothesis: str, test: Dict[str, np.array], top_k=10, perplexity_threshold=6., beta=1.):\n",
    "    nli_scores = perform_nli(premise, hypothesis)\n",
    "    perplexity_score = estimate_perplexity(premise)\n",
    "    \n",
    "    if hypothesis not in test:\n",
    "        raise Exception(\"There are no ready embeddings for this hypothesis!\")\n",
    "    else:\n",
    "        distance_score = get_mean_dist(premise, test[hypothesis])\n",
    "    \n",
    "    divisor = max(1., np.exp(perplexity_score - perplexity_threshold))\n",
    "    nli_quality = 1 - nli_scores[\"contradiction\"]\n",
    "    \n",
    "    f_score = (1 + beta ** 2) * nli_quality * distance_score / (beta ** 2 * nli_quality + distance_score)\n",
    "    return {\n",
    "        \"nli_quality\": nli_quality,\n",
    "        \"distance_score\": distance_score,\n",
    "        \"perplexity_divisor\": divisor,\n",
    "        \"final\": f_score / divisor\n",
    "    }\n",
    "\n",
    "with open(\"data/embeddings.json\") as f:\n",
    "    hypothesis_files = json.load(f)\n",
    "embeddings = {text: torch.load(file).numpy() for text, file in hypothesis_files.items()}\n",
    "\n",
    "nli_tokenizer = AutoTokenizer.from_pretrained('cointegrated/rubert-base-cased-nli-threeway')\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('cointegrated/rubert-base-cased-nli-threeway')\n",
    "\n",
    "sbert_tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
    "sbert_model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
    "\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/rugpt3small_based_on_gpt2')\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('sberbank-ai/rugpt3small_based_on_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of torch.overrides failed: Traceback (most recent call last):\n",
      "  File \"/home/data_sapiens/.local/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/data_sapiens/.local/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 848, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/data_sapiens/.local/lib/python3.8/site-packages/torch/overrides.py\", line 1365, in <module>\n",
      "    has_torch_function = _add_docstr(\n",
      "RuntimeError: function '_has_torch_function' already has a docstring\n",
      "]\n",
      "[autoreload of torch.cuda.amp.autocast_mode failed: Traceback (most recent call last):\n",
      "  File \"/home/data_sapiens/.local/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/data_sapiens/.local/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 848, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/data_sapiens/.local/lib/python3.8/site-packages/torch/cuda/amp/autocast_mode.py\", line 11, in <module>\n",
      "    class autocast(torch.autocast_mode.autocast):\n",
      "AttributeError: module 'torch' has no attribute 'autocast_mode'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "premise1 = \"Иван любит собирать грибы.\"\n",
    "premise2 = \"Ивана похитили инопланетяне и оставили одного в лесу в сапогах.\"\n",
    "hypothesis = \"На ногах у Ивана резиновые сапоги. Иван ходит по лесу с ножом и корзиной.\"\n",
    "\n",
    "res1 = score(premise1, hypothesis, embeddings)\n",
    "res2 = score(premise2, hypothesis, embeddings)\n",
    "\n",
    "pprint({premise1: res1, premise2: res2})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
